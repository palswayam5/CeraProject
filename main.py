# -*- coding: utf-8 -*-
"""CERAMD - Clinical Engagement Reasoning and Medical Diagnosis

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/sdrive/1TUQoDFrNihX_D3XQhzEhz64xU3Asz8g7

NECESSARY IMPORTS
"""

import requests
import time
import os

# API settings - Using Mixtral which has better medical reasoning capabilities
HF_API_TOKEN = os.environ.get("HF_API_TOKEN")
MODEL_NAME = "mistralai/Mixtral-8x7B-Instruct-v0.1"  # More powerful free model

def ask_gemini(patient_history, temperature=0.5):
    """
    Use Hugging Face Inference API to conduct a medical consultation.
    
    Parameters:
    - patient_history: The accumulated patient information so far
    - temperature: Controls randomness (0.0 = deterministic, 1.0 = creative)
    
    Returns:
    - Model's response as text
    """
    # API endpoint for Hugging Face Inference API
    API_URL = f"https://api-inference.huggingface.co/models/{MODEL_NAME}"
    
    # Headers for the API request
    headers = {"Authorization": f"Bearer {HF_API_TOKEN}"}
    
    # Prepare a much more detailed prompt with clear instructions
    prompt = f"""[INST] You are a medical reasoning system conducting an interactive patient consultation.

PATIENT HISTORY:
{patient_history}

Based on the information gathered so far, what is ONE specific follow-up question you need to ask the patient next?
Ask only ONE question that would be most helpful to clarify the diagnosis.
If you have gathered sufficient information for a diagnosis, respond with "DIAGNOSIS_READY" instead of a question. [/INST]"""


    # Parameters for the API request
    payload = {
        "inputs": prompt,
        "parameters": {
            "max_new_tokens": 200,
            "temperature": temperature,
            "do_sample": True,
            "top_p": 0.9,
            "return_full_text": False
        }
    }
    
    # Make the API request
    response = requests.post(API_URL, headers=headers, json=payload)
    
    # Process and return the response
    if response.status_code == 200:
        result = response.json()
        # Extract generated text from the response
        if isinstance(result, list) and len(result) > 0:
            generated_text = result[0].get("generated_text", "")
            return generated_text.strip()
        return str(result)
    else:
        return f"Error: {response.status_code}, {response.text}"

def generate_diagnosis(patient_history, temperature=0.2):
    """
    Generate a diagnosis and prescription based on gathered patient information.
    
    Parameters:
    - patient_history: The complete patient information collected
    - temperature: Lower temperature for more precise medical advice
    
    Returns:
    - Diagnosis and prescription as text
    """
    # API endpoint for Hugging Face Inference API
    API_URL = f"https://api-inference.huggingface.co/models/{MODEL_NAME}"
    
    # Headers for the API request
    headers = {"Authorization": f"Bearer {HF_API_TOKEN}"}
    
    # Enhanced diagnostic prompt with structured analysis requirements
    diagnosis_prompt = f"""<s>[INST] You are an experienced AI medical assistant tasked with analyzing patient information and providing a preliminary assessment.

COMPLETE PATIENT HISTORY:
{patient_history}

Please provide a comprehensive analysis following this structure:

1. SUMMARY OF KEY SYMPTOMS AND FINDINGS
   - List the most significant symptoms, their duration, and severity
   - Note any relevant medical history and risk factors

2. DIFFERENTIAL DIAGNOSIS
   - List 2-3 most likely conditions based on the presented symptoms
   - For each potential diagnosis, explain why it matches the symptoms
   - Indicate which diagnosis appears most probable and why

3. RECOMMENDED NEXT STEPS
   - Suggest appropriate diagnostic tests or examinations
   - Recommend general self-care measures
   - Provide clear guidance on when to seek immediate medical attention

4. IMPORTANT DISCLAIMERS
   - Emphasize this is a preliminary assessment only
   - Advise consultation with a licensed healthcare professional

Remember to maintain a professional, evidence-based approach while explaining medical concepts in clear, accessible language.
[/INST]"""

    # Parameters for the API request
    payload = {
        "inputs": diagnosis_prompt,
        "parameters": {
            "max_new_tokens": 800,
            "temperature": temperature,
            "do_sample": True,
            "top_p": 0.85,
            "return_full_text": False
        }
    }
    
    # Make the API request
    response = requests.post(API_URL, headers=headers, json=payload)
    
    # Process and return the response
    if response.status_code == 200:
        result = response.json()
        # Extract generated text from the response
        if isinstance(result, list) and len(result) > 0:
            generated_text = result[0].get("generated_text", "")
            return generated_text.strip()
        return str(result)
    else:
        return f"Error: {response.status_code}, {response.text}"

# def get_text_input(prompt):
#     """
#     Gets text input from the user through the console.
#     """
#     return input(prompt)

# def run_medical_consultation():
#     """
#     Run an interactive medical consultation that collects symptoms via text input
#     until ready for diagnosis.
#     """
#     print("\n" + "="*60)
#     print("  CERAMD - Clinical Engagement Reasoning and Medical Diagnosis")
#     print("="*60)
#     print("\nDISCLAIMER:")
#     print("This system is for educational and demonstration purposes only.")
#     print("It does not provide medical advice or replace consultation with")
#     print("licensed healthcare professionals. Always seek proper medical")
#     print("attention for health concerns.\n")
#     print("="*60 + "\n")

#     # Get initial symptoms via text input with more detailed prompt
#     initial_symptoms = get_text_input("Please describe your main symptoms and when they started: ")
#     patient_history = f"Initial complaint: {initial_symptoms}"

#     # Consultation loop
#     consultation_active = True
#     question_count = 0
#     max_questions = 10  # Safety limit to prevent infinite loops
    
#     while consultation_active and question_count < max_questions:
#         print("\nAnalyzing information...")
#         response = ask_llm(patient_history)
#         question_count += 1

#         # Check if AI signals readiness for diagnosis
#         if "DIAGNOSIS_READY" in response:
#             print("\nThank you for providing all the necessary information.")
#             print("Generating preliminary assessment...\n")
#             consultation_active = False
#             continue

#         print(f"\nDoctor AI: {response}")
#         answer = get_text_input("Your response: ")

#         # Append Q&A to patient history with clear formatting
#         patient_history += f"\n\nQuestion {question_count}: {response}\nPatient Answer: {answer}"

#     # Generate and display diagnosis
#     print("\nAnalyzing your condition. Please wait...")
#     diagnosis = generate_diagnosis(patient_history)
#     print("\n" + "="*60)
#     print("                PRELIMINARY ASSESSMENT")
#     print("="*60 + "\n")
#     print(diagnosis)
#     print("\n" + "="*60)
#     print("REMINDER: This is not a medical diagnosis. Please consult")
#     print("with a healthcare professional for proper medical advice.")
#     print("="*60)

#     # Save the consultation to a file
#     timestamp = time.strftime("%Y%m%d-%H%M%S")
#     filename = f"medical_consultation_{timestamp}.txt"
#     with open(filename, "w") as f:
#         f.write("="*60 + "\n")
#         f.write("  CERAMD - Clinical Engagement Reasoning and Medical Diagnosis\n")
#         f.write("="*60 + "\n\n")
#         f.write("=== PATIENT HISTORY ===\n\n")
#         f.write(patient_history)
#         f.write("\n\n=== PRELIMINARY ASSESSMENT ===\n\n")
#         f.write(diagnosis)
#         f.write("\n\n" + "="*60 + "\n")
#         f.write("REMINDER: This is not a medical diagnosis. Please consult\n")
#         f.write("with a healthcare professional for proper medical advice.\n")
#         f.write("="*60 + "\n")

#     print(f"\nConsultation saved to {filename}")

# # Alternative API option using Together.ai if preferred
# def use_together_ai(patient_history, model_name="mistralai/Mixtral-8x7B-Instruct-v0.1", temperature=0.5):
#     """
#     Alternative implementation using Together.ai API (they offer free credits)
    
#     Parameters:
#     - patient_history: The accumulated patient information so far
#     - model_name: The model to use
#     - temperature: Controls randomness
    
#     Returns:
#     - Model's response as text
#     """
#     # API endpoint for Together.ai API
#     API_URL = "https://api.together.xyz/v1/completions"
    
#     # Get the API token from environment variable
#     api_token = os.environ.get("TOGETHER_API_KEY")
    
#     # Headers for the API request
#     headers = {
#         "Authorization": f"Bearer {api_token}",
#         "Content-Type": "application/json"
#     }
    
#     # Same enhanced prompt as before
#     prompt = f"""<s>[INST] You are a highly trained medical reasoning system conducting a step-by-step patient consultation.

# Your goal is to identify the most likely diagnosis by asking targeted, relevant questions one at a time.

# PATIENT HISTORY SO FAR:
# {patient_history}

# INSTRUCTIONS:
# 1. Analyze the current patient information carefully
# 2. Determine the most important piece of information needed next
# 3. Ask exactly ONE specific, clear follow-up question that will help narrow down possible diagnoses
# 4. Phrase your question in a patient-friendly, conversational manner
# 5. If you believe you have sufficient information to provide a preliminary diagnosis, respond with "DIAGNOSIS_READY" instead of a question

# IMPORTANT: 
# - Focus on symptoms, duration, severity, aggravating/alleviating factors, and relevant medical history
# - Do not ask multiple questions at once
# - Maintain a compassionate, professional tone
# [/INST]"""

#     # Parameters for the API request
#     payload = {
#         "model": model_name,
#         "prompt": prompt,
#         "max_tokens": 200,
#         "temperature": temperature,
#         "top_p": 0.9
#     }
    
#     # Make the API request
#     response = requests.post(API_URL, headers=headers, json=payload)
    
#     # Process and return the response
#     if response.status_code == 200:
#         result = response.json()
#         return result.get("choices", [{}])[0].get("text", "").strip()
#     else:
#         return f"Error: {response.status_code}, {response.text}"

# # Run the program
# if __name__ == "__main__":
#     run_medical_consultation()